{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, GRU, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdw_vec = pd.read_csv('../data/cat_train_HDW_MMAO15.csv',nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>tot_min</th>\n",
       "      <th>A01-1_Headway_0</th>\n",
       "      <th>A01-1_Headway_1</th>\n",
       "      <th>A01-1_Headway_2</th>\n",
       "      <th>A01-2_Headway_0</th>\n",
       "      <th>A01-2_Headway_1</th>\n",
       "      <th>A01-2_Headway_2</th>\n",
       "      <th>A02-1_Headway_0</th>\n",
       "      <th>A02-1_Headway_1</th>\n",
       "      <th>...</th>\n",
       "      <th>N02-2_Headway_2</th>\n",
       "      <th>N03-1_Headway_0</th>\n",
       "      <th>N03-1_Headway_1</th>\n",
       "      <th>N03-1_Headway_2</th>\n",
       "      <th>N03-2_Headway_0</th>\n",
       "      <th>N03-2_Headway_1</th>\n",
       "      <th>N03-2_Headway_2</th>\n",
       "      <th>N04-1_Headway_0</th>\n",
       "      <th>N04-1_Headway_1</th>\n",
       "      <th>N04-1_Headway_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-3-1 7:59</td>\n",
       "      <td>85439.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-3-1 8:0</td>\n",
       "      <td>85440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-3-1 8:1</td>\n",
       "      <td>85441.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-3-1 8:2</td>\n",
       "      <td>85442.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-3-1 8:3</td>\n",
       "      <td>85443.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        datetime  tot_min  A01-1_Headway_0  A01-1_Headway_1  A01-1_Headway_2  \\\n",
       "0  2015-3-1 7:59  85439.0                0                0                0   \n",
       "1   2015-3-1 8:0  85440.0                1                0                0   \n",
       "2   2015-3-1 8:1  85441.0                0                1                0   \n",
       "3   2015-3-1 8:2  85442.0                0                0                1   \n",
       "4   2015-3-1 8:3  85443.0                0                1                0   \n",
       "\n",
       "   A01-2_Headway_0  A01-2_Headway_1  A01-2_Headway_2  A02-1_Headway_0  \\\n",
       "0                0                0                0                0   \n",
       "1                1                0                0                1   \n",
       "2                1                0                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                1                0                1   \n",
       "\n",
       "   A02-1_Headway_1       ...         N02-2_Headway_2  N03-1_Headway_0  \\\n",
       "0                0       ...                       0                0   \n",
       "1                0       ...                       0                1   \n",
       "2                1       ...                       0                0   \n",
       "3                1       ...                       0                1   \n",
       "4                0       ...                       0                0   \n",
       "\n",
       "   N03-1_Headway_1  N03-1_Headway_2  N03-2_Headway_0  N03-2_Headway_1  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                1   \n",
       "2                1                0                1                0   \n",
       "3                0                0                0                1   \n",
       "4                0                1                1                0   \n",
       "\n",
       "   N03-2_Headway_2  N04-1_Headway_0  N04-1_Headway_1  N04-1_Headway_2  \n",
       "0                0                0                0                0  \n",
       "1                0                1                0                0  \n",
       "2                0                0                1                0  \n",
       "3                0                1                0                0  \n",
       "4                0                0                0                1  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdw_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = hdw_vec['tot_min'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xh_tt = []\n",
    "yh_tt = []\n",
    "for i in range(30,len(hdw_vec)-30):\n",
    "    if t[i] - t[i-30] == 30. and t[i+30] - t[i] == 30.:\n",
    "        x_vec = []\n",
    "        x_vec.append(hdw_vec.loc[i-30][2:].tolist())\n",
    "        x_vec.append(hdw_vec.loc[i-15][2:].tolist())\n",
    "        x_vec.append(hdw_vec.loc[i][2:].tolist())\n",
    "        xh_tt.append(x_vec)\n",
    "        y_vec = []\n",
    "        y_vec.append(hdw_vec.loc[i+15][2:].tolist())\n",
    "        y_vec.append(hdw_vec.loc[i+30][2:].tolist())\n",
    "        yh_tt.append(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xh2 = np.asarray(xh_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9340, 3, 513)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xh2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  0\n",
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n"
     ]
    }
   ],
   "source": [
    "xh_tt = []\n",
    "yh_tt = []\n",
    "tt = []\n",
    "chunk = 10000\n",
    "k = -1\n",
    "for hdw_vec in pd.read_csv('../data/cat_train_HDW_MMAO15.csv',chunksize=chunk):\n",
    "    print('iter ',k+1)\n",
    "    k += 1\n",
    "    t = hdw_vec['tot_min'].tolist()\n",
    "    for i in range(30+k*chunk,len(hdw_vec)-30+k*chunk):\n",
    "        if t[i-k*chunk] - t[i-30-k*chunk] == 30.  \\\n",
    "                      and t[i+30-k*chunk] - t[i-k*chunk] == 30.:\n",
    "            x_vec = []\n",
    "            x_vec.append(hdw_vec.loc[i-30][2:].tolist())\n",
    "            x_vec.append(hdw_vec.loc[i-15][2:].tolist())\n",
    "            x_vec.append(hdw_vec.loc[i][2:].tolist())\n",
    "            xh_tt.append(x_vec)\n",
    "            y_vec = []\n",
    "            y_vec.append(hdw_vec.loc[i+15][2:].tolist())\n",
    "            y_vec.append(hdw_vec.loc[i+30][2:].tolist())\n",
    "            yh_tt.append(y_vec)\n",
    "            tt.append(t[i+30-k*chunk])\n",
    "    if len(xh_tt) > 60000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65020, 3, 513)\n",
      "(65020, 2, 513)\n"
     ]
    }
   ],
   "source": [
    "xh2 = np.asarray(xh_tt)\n",
    "yh2 = np.asarray(yh_tt)\n",
    "print(xh2.shape)\n",
    "print(yh2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del xh_tt\n",
    "del yh_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 3\n",
    "max_decoder_seq_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = 513\n",
    "num_decoder_tokens = 513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input_data = xh2\n",
    "decoder_target_data = yh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = []\n",
    "decoder_start = [0.5] * 513\n",
    "for i in range(len(yh2)):\n",
    "    yi_seq = []\n",
    "    yi_seq.append(decoder_start)\n",
    "    yi_seq.append(yh2[i][0])\n",
    "    decoder_input_data.append(yi_seq)\n",
    "decoder_input_data = np.asarray(decoder_input_data, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xh2, yh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65020, 2, 513)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after the model of https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "\n",
    "# encoder architecture\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# retain final state to condition decoder; discard encoder output seq\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder architecture\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='sigmoid')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model ... inputs are to encoder and decoder, respectively; output from decoder only\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD with Adam optimizer, crossentropy loss\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "65020/65020 [==============================] - 136s - loss: 896.1761 - acc: 4.0757e-04   \n",
      "Epoch 2/2\n",
      "65020/65020 [==============================] - 123s - loss: 888.0690 - acc: 8.3820e-04   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b7070afe80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    pred_seq = []\n",
    "    # Encode the input into state to pass to decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    for i in range(num_decoder_tokens):\n",
    "        target_seq[0, 0, i] = 0.5\n",
    "\n",
    "    for i in range(2):\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        pred_seq.append(output_tokens.reshape(num_decoder_tokens).tolist())\n",
    "        # Update the target sequence\n",
    "        target_seq = output_tokens\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return pred_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seq=[]\n",
    "for seq_index in range(len(encoder_input_data)-1):\n",
    "    input_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    pred_seq.append(decode_sequence(input_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65019, 2, 513)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_s = np.asarray(pred_seq)\n",
    "pred_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenz(loc_vec):  # three element probability output for platform HDW state at +15 min or +30 min\n",
    "    vec_max = max(loc_vec)\n",
    "    if vec_max < 0.33:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.argmax(loc_vec) + 1\n",
    "# token def'n:  0 = [0,0,0] = nan, 1 = [1,0,0], 2 = [0,1,0], 3 = [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_tok_15 = []\n",
    "pred_tok_30 = []\n",
    "for i in range(len(pred_seq)):\n",
    "    vec_15 = []\n",
    "    vec_30 = []\n",
    "    for j in range(171):\n",
    "        loc_15 = pred_seq[i][0][3*j:3*(j+1)]\n",
    "        loc_30 = pred_seq[i][1][3*j:3*(j+1)]\n",
    "        vec_15.append(tokenz(loc_15))\n",
    "        vec_30.append(tokenz(loc_30))\n",
    "    pred_tok_15.append(vec_15)\n",
    "    pred_tok_30.append(vec_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65019, 171)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_t15 = np.asarray(pred_tok_15)\n",
    "pred_t15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_name = '../data/pred_tok_15_lrg.pkl'\n",
    "f_obj = open(f_name,'wb')\n",
    "pickle.dump(pred_tok_15,f_obj)\n",
    "f_obj.close()\n",
    "f_name = '../data/pred_tok_30_lrg.pkl'\n",
    "f_obj = open(f_name,'wb')\n",
    "pickle.dump(pred_tok_30,f_obj)\n",
    "f_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_name = '../data/tot_time_30_lrg.pkl'\n",
    "f_obj = open(f_name,'wb')\n",
    "pickle.dump(tt,f_obj)\n",
    "f_obj.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
